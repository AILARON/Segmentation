{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CityscapesInstanceEvaluator' from 'detectron2.evaluation' (/home/sondreab/Desktop/detectron2/detectron2/evaluation/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b6efca5d5c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_on_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPascalVOCDetectionEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCityscapesInstanceEvaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCityscapesSemSegEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CityscapesInstanceEvaluator' from 'detectron2.evaluation' (/home/sondreab/Desktop/detectron2/detectron2/evaluation/__init__.py)"
     ]
    }
   ],
   "source": [
    "#Based on the tutorial found at https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5\n",
    "#Master\n",
    "\n",
    "import torch, torchvision\n",
    "print(torch.__version__)\n",
    "\n",
    "# Some basic setup\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import csv\n",
    "import itertools\n",
    "import random\n",
    "import collections\n",
    "from utils import *\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.evaluation import PascalVOCDetectionEvaluator\n",
    "from detectron2.evaluation import CityscapesInstanceEvaluator, CityscapesSemSegEvaluator\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "from pysilcam.config import PySilcamSettings\n",
    "from pysilcam.process import extract_roi\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sondreab/Desktop/DATA/copepod_lab_petridish/output/model_2020.07.11_00:52:26\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "DIRECTORY = '/home/sondreab/Desktop/DATA/copepod_lab_petridish'\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "runtime = strftime(\"%Y.%m.%d_%H:%M:%S\", gmtime())\n",
    "\n",
    "DATA_DIR = DIRECTORY + '/copepods'\n",
    "VISUALIZE_DIR = DIRECTORY + '/visualize/'+ runtime\n",
    "INFERENCE_DIR = DIRECTORY + '/inference/' + runtime\n",
    "\n",
    "DATASET = 'copepods'\n",
    "\n",
    "OUTPUT_PATH = DIRECTORY + \"/output/\" + \"model_\" + runtime\n",
    "cfg.OUTPUT_DIR = OUTPUT_PATH\n",
    "#os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "print(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code in cell is from https://gist.github.com/ortegatron/c0dad15e49c2b74de8bb09a5615d9f6b\n",
    "\n",
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "import detectron2.utils.comm as comm\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "    \n",
    "    def _do_loss_eval(self):\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "            \n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):            \n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "            \n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop \n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "        \n",
    "        \n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            self._do_loss_eval()\n",
    "        self.trainer.storage.put_scalars(timetest=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code in cell is from https://gist.github.com/ortegatron/c0dad15e49c2b74de8bb09a5615d9f6b\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "                     \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1,LossEvalHook(\n",
    "            cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg,True)\n",
    "            )\n",
    "        ))\n",
    "        return hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(data, file_name, directory=DIRECTORY):\n",
    "    json_file = os.path.join(directory, file_name + '.json')\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_name, directory=DIRECTORY):\n",
    "    json_file = os.path.join(directory, file_name+'.json')\n",
    "    with open(json_file) as f:\n",
    "        dataset = json.load(f)\n",
    "    for record in dataset:\n",
    "        for obj in record['annotations']:\n",
    "            obj[\"bbox_mode\"] = BoxMode.XYXY_ABS\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_visualization(dataset, directory=VISUALIZE_DIR):\n",
    "    savepath = VISUALIZE_DIR\n",
    "    print(\"Savepath: {}\".format(savepath))\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    dataset_metadata = MetadataCatalog.get(dataset)\n",
    "    dataset_dicts = read_json_file(dataset, DIRECTORY)\n",
    "    print('Saving dataset '+ dataset)\n",
    "    for image in dataset_dicts:\n",
    "        img = cv2.imread(image[\"file_name\"])\n",
    "        visualizer = Visualizer(img[:, :, ::-1], metadata=dataset_metadata, scale=1)\n",
    "        vis = visualizer.draw_dataset_dict(image)\n",
    "        \n",
    "        cv2.imwrite(os.path.join(savepath, '.'.join(image['file_name'].split('/')[-1].split('.')[:-1]) + '.png'), vis.get_image()[:, :, ::-1])\n",
    "        print('.'.join(image['file_name'].split('/')[-1].split('.')[:-1])+ ' saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_coco_dataset_visualization(dataset,dataset_dir = OUTPUT_PATH, directory=VISUALIZE_DIR):\n",
    "    savepath = VISUALIZE_DIR\n",
    "    print(\"Savepath: {}\".format(savepath))\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    dataset_metadata = MetadataCatalog.get(dataset)\n",
    "    dataset_dicts = read_json_file(dataset, DIRECTORY)\n",
    "    print('Saving dataset '+ dataset)\n",
    "    for image in dataset_dicts:\n",
    "        img = cv2.imread(image[\"file_name\"])\n",
    "        visualizer = Visualizer(img[:, :, ::-1], metadata=dataset_metadata, scale=1)\n",
    "        vis = visualizer.draw_dataset_dict(image)\n",
    "        \n",
    "        cv2.imwrite(os.path.join(savepath, '.'.join(image['file_name'].split('/')[-1].split('.')[:-1]) + '.png'), vis.get_image()[:, :, ::-1])\n",
    "        print('.'.join(image['file_name'].split('/')[-1].split('.')[:-1])+ ' saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_dataset(directory = DIRECTORY):\n",
    "    thing_classes = ['oil', 'other', 'bubble', 'faremoteecal_pellets', 'copepod', 'diatom_chain', 'oily_gas']\n",
    "    for d in [\"train\", \"val\"]:\n",
    "        DatasetCatalog.register(\"copepod_\" + d, lambda d=d: read_json_file(d, DIRECTORY))\n",
    "        MetadataCatalog.get(\"copepod_\" + d).set(thing_classes=thing_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataset(dataset):\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    #cfg.merge_from_list([\"MODEL.WEIGHTS\", os.path.join(DIRECTORY, \"output/model_final.pth\")])\n",
    "    cfg.DATASETS.TRAIN = (dataset,)\n",
    "    cfg.DATASETS.TEST = ()\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "    cfg.SOLVER.MAX_ITER = 500    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7  # only has one class (ballon)\n",
    "\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = DefaultTrainer(cfg) \n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_over_directory(dataset,\n",
    "                             files_dir,\n",
    "                             output_path = OUTPUT_PATH, \n",
    "                             inference_dir = os.path.join(DIRECTORY, INFERENCE_DIR)):\n",
    "    mypath = files_dir\n",
    "    onlyfiles = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "    \n",
    "    cfg.MODEL.WEIGHTS = os.path.join(OUTPUT_PATH, \"model_final.pth\")\n",
    "    \n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model   \n",
    "    \n",
    "    cfg.DATASETS.TEST = (dataset, )\n",
    "\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    savepath = inference_dir\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    \n",
    "    dataset_metadata = MetadataCatalog.get(dataset)\n",
    "    \n",
    "    image_list = onlyfiles\n",
    "    \n",
    "    for image in image_list:\n",
    "        print(os.path.join(mypath,image))\n",
    "        im = cv2.imread(os.path.join(mypath,image))\n",
    "        outputs = predictor(im)\n",
    "        \n",
    "        vis = Visualizer(im[:, :, ::-1],\n",
    "                    metadata=dataset_metadata, \n",
    "                    scale=0.5, \n",
    "                    instance_mode=ColorMode.IMAGE  # remove the colors of unsegmented pixels\n",
    "            )\n",
    "        v = vis.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        cv2.imwrite(os.path.join(savepath, '.'.join(image.split('.')[:-1]) + '.png'), v.get_image()[:, :, ::-1])\n",
    "    print(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [\"train\",  \"val\", \"test\"]\n",
    "thing_classes = ['oil', 'other', 'bubble', 'faecal_pellets', 'copepod', 'diatom_chain', 'oily_gas']\n",
    "for set_ in sets:\n",
    "    dataset = \"my_dataset_\"+set_\n",
    "    file = \"my_dataset_\"+set_\n",
    "    DatasetCatalog.register(dataset, lambda d=file: read_json_file(d, DIRECTORY))\n",
    "    MetadataCatalog.get(dataset).set(thing_classes=thing_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "sets = [\"train\",  \"val\", \"test\"]\n",
    "for d in sets:\n",
    "    register_coco_instances(\"my_coco_dataset_\"+d, \n",
    "                            {}, \n",
    "                            \"/home/sondreab/Desktop/DATA/copepod_lab_petridish/my_coco_dataset_\"+d+\".json\", \n",
    "                            \"/home/sondreab/Desktop/DATA/copepod_lab_petridish/copepods\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"coco2017val\", \n",
    "                            {}, \n",
    "                            \"/home/sondreab/Desktop/detectron2/datasets/coco/annotations/instances_val2017.json\", \n",
    "                            \"/home/sondreab/Desktop/detectron2/datasets/coco/val2017\")\n",
    "register_coco_instances(\"coco2017val_100\", \n",
    "                            {}, \n",
    "                            \"/home/sondreab/Desktop/detectron2/datasets/coco/annotations/instances_val2017_100.json\", \n",
    "                            \"/home/sondreab/Desktop/detectron2/datasets/coco/val2017\")\n",
    "register_coco_instances(\"coco2017test\", \n",
    "                            {}, \n",
    "                            \"/home/sondreab/Desktop/detectron2/datasets/coco/annotations/image_info_test2017.json\", \n",
    "                            \"/home/sondreab/Desktop/detectron2/datasets/coco/test2017\")\n",
    "register_coco_instances(\"coco2017testdev\", \n",
    "                            {}, \n",
    "                            \"/home/sondreab/Desktop/detectron2/datasets/coco/annotations/image_info_test-dev2017.json\", \n",
    "                            \"/home/sondreab/Desktop/detectron2/datasets/coco/test2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/11 02:52:26 d2.data.datasets.cityscapes]: \u001b[0mPreprocessing cityscapes annotations ...\n",
      "\u001b[32m[07/11 02:52:27 d2.data.datasets.cityscapes]: \u001b[0mLoaded 1525 images from /home/sondreab/Desktop/detectron2/datasets/cityscapes/leftImg8bit/test\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets import load_cityscapes_instances\n",
    "create_json_file(data = load_cityscapes_instances(image_dir = \"/home/sondreab/Desktop/detectron2/datasets/cityscapes/leftImg8bit/test\", \n",
    "                                     gt_dir = \"/home/sondreab/Desktop/detectron2/datasets/cityscapes/gtFine/test\", \n",
    "                                     from_json=True, \n",
    "                                     to_polygons=True), \n",
    "                 file_name = \"cityscapes_test\", \n",
    "                 directory=DIRECTORY\n",
    "                )\n",
    "\n",
    "DatasetCatalog.register(\"cityscapestest\", lambda d=\"cityscapes_test\": read_json_file(d, DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'register_pascal_voc' from 'detectron2.data.datasets' (/home/sondreab/Desktop/detectron2/detectron2/data/datasets/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-147ecc1d6751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_pascal_voc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mregister_pascal_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pVOC12test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/home/sondreab/Desktop/detectron2/datasets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2012\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'register_pascal_voc' from 'detectron2.data.datasets' (/home/sondreab/Desktop/detectron2/detectron2/data/datasets/__init__.py)"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets import register_pascal_voc\n",
    "\n",
    "register_pascal_voc(\"pVOC12test\", \"/home/sondreab/Desktop/detectron2/datasets\", \"test\", 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Cityscapes\" \n",
    "    #\"COCO-InstanceSegmentation\"\n",
    "    #\"COCO-Detection\"\n",
    "    #\"Cityscapes\"\n",
    "arch_backbone = \"mask_rcnn_R_50_FPN\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "#runtime = strftime(\"%Y.%m.%d_%H:%M:%S\", gmtime())\n",
    "\n",
    "OUTPUT_PATH = DIRECTORY + \"/output/\" + \"model_cityscapes_\" + arch_backbone + \"_\" + runtime\n",
    "cfg.OUTPUT_DIR = OUTPUT_PATH\n",
    "#os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "print(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(task + \"/\" + arch_backbone + \".yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_coco_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_coco_dataset_val\",)\n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(task + \"/\" + arch_backbone + \".yaml\")  # Let training initialize from model\n",
    "\"\"\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  \n",
    "cfg.SOLVER.MAX_ITER = 20000  # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "#cfg.SOLVER.CHECKPOINT_PERIOD = 2000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 5   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7\n",
    "#cfg.MODEL.RETINANET.NUM_CLASSES = 7\n",
    "\"\"\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = MyTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "#trainer.train()\n",
    "\n",
    "AP_EVAL_METRICS = {}\n",
    "\n",
    "\n",
    "model = model_zoo.get(task + \"/\" + arch_backbone + \".yaml\", trained=True)\n",
    "\n",
    "\n",
    "#evaluator = COCOEvaluator(\"coco2017val\", cfg, False, output_dir=OUTPUT_PATH)\n",
    "#val_loader = build_detection_test_loader(cfg, \"coco2017val\")\n",
    "\n",
    "evaluator = CityscapesInstanceEvaluator(\"cityscapestest\") \n",
    "val_loader = build_detection_test_loader(cfg, \"cityscapestest\")\n",
    "metrics = inference_on_dataset(model, val_loader, evaluator)\n",
    "AP_EVAL_METRICS = metrics\n",
    "\n",
    "create_json_file(AP_EVAL_METRICS, \"AP_eval_metrics\", OUTPUT_PATH)\n",
    "\n",
    "evaluator = CityscapesSemSegEvaluator(\"cityscapestest\")\n",
    "metrics = inference_on_dataset(model, val_loader, evaluator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = COCOEvaluator(\"coco2017testdev\", cfg, False, output_dir=OUTPUT_PATH)\n",
    "val_loader = build_detection_test_loader(cfg, \"coco2017testdev\")\n",
    "coco_metrics = inference_on_dataset(model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dataset, \n",
    "              output_path = OUTPUT_PATH, \n",
    "              inference_dir = os.path.join(DIRECTORY, INFERENCE_DIR), \n",
    "              weights = \"model_final.pth\"):\n",
    "    \n",
    "    \n",
    "    cfg.MODEL.WEIGHTS = os.path.join(output_path, weights)\n",
    "    \n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model   \n",
    "    \n",
    "    cfg.DATASETS.TEST = (dataset, )\n",
    "    \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    savepath = inference_dir\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    \n",
    "    dataset_metadata = MetadataCatalog.get(dataset)\n",
    "    dataset_dicts = read_json_file(dataset, DIRECTORY)\n",
    "    \n",
    "    for image in dataset_dicts:    \n",
    "        im = cv2.imread(image[\"file_name\"])\n",
    "        outputs = predictor(im)\n",
    "        #print(outputs)\n",
    "        #create_json_file(outputs, 'outputs')\n",
    "        \n",
    "        vis = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=dataset_metadata, \n",
    "                   scale=0.5, \n",
    "                   instance_mode=ColorMode.IMAGE  # remove the colors of unsegmented pixels\n",
    "        )\n",
    "        v = vis.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        #cv2.imshow('prediction',v.get_image()[:, :, ::-1])\n",
    "        #cv2.waitKey(0)\n",
    "        cv2.imwrite(os.path.join(savepath, '.'.join(image['file_name'].split('/')[-1].split('.')[:-1]) + '.png'), v.get_image()[:, :, ::-1])\n",
    "    print(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(\"my_dataset_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_visualization(\"my_dataset_train\", VISUALIZE_DIR)\n",
    "save_dataset_visualization(\"my_dataset_val\", VISUALIZE_DIR)\n",
    "save_dataset_visualization(\"my_dataset_test\", VISUALIZE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_visualization(\"my_coco_dataset_train\", VISUALIZE_DIR)\n",
    "save_dataset_visualization(\"my_coco_dataset_val\", VISUALIZE_DIR)\n",
    "save_dataset_visualization(\"my_coco_dataset_test\", VISUALIZE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_over_directory(dataset= \"my_dataset_test\",\n",
    "                         files_dir = os.path.join(DIRECTORY,\"RAWbmp\"),\n",
    "                         output_path = OUTPUT_PATH, \n",
    "                         inference_dir = os.path.join(DIRECTORY, INFERENCE_DIR)+\"_mission_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:segmentation] *",
   "language": "python",
   "name": "conda-env-segmentation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
